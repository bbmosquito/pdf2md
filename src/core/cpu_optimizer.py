"""
AMD CPUå¤šæ ¸æ€§èƒ½ä¼˜åŒ–å™¨

ä¸“é—¨é’ˆå¯¹AMD Ryzen 9 3950X/3990Xç­‰16æ ¸32çº¿ç¨‹å¤„ç†å™¨ä¼˜åŒ–
ç›®æ ‡ï¼šå……åˆ†åˆ©ç”¨æ‰€æœ‰ç‰©ç†æ ¸å¿ƒï¼Œè¾¾æˆæœ€é«˜ååé‡
"""

import psutil
import gc
import logging
from typing import Dict, Optional, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class SystemSpec:
    """ç³»ç»Ÿè§„æ ¼"""
    physical_cores: int
    logical_cores: int
    total_memory_gb: float
    available_memory_gb: float


@dataclass
class OptimalConfig:
    """æœ€ä¼˜é…ç½®"""
    max_workers: int
    num_threads: int
    ocr_batch_size: int
    layout_batch_size: int
    table_batch_size: int
    max_process_memory_gb: float

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'max_workers': self.max_workers,
            'num_threads': self.num_threads,
            'ocr_batch_size': self.ocr_batch_size,
            'layout_batch_size': self.layout_batch_size,
            'table_batch_size': self.table_batch_size,
        }


class AMDCPUOptimizer:
    """
    AMD CPUæ€§èƒ½ä¼˜åŒ–å™¨

    æ™ºèƒ½è®¡ç®—æœ€ä¼˜é…ç½®ä»¥å……åˆ†åˆ©ç”¨16ä¸ªç‰©ç†æ ¸å¿ƒ
    """

    # ä¸åŒå†…å­˜é…ç½®ä¸‹çš„æ¨èå‚æ•°
    RECOMMENDED_CONFIGS = {
        # (æ€»å†…å­˜GB, æ˜¯å¦GPU): {é…ç½®}
        (16, False): {'workers': 8, 'batch': 8, 'threads': 16},
        (32, False): {'workers': 16, 'batch': 32, 'threads': 32},
        (64, False): {'workers': 16, 'batch': 48, 'threads': 32},
        (96, False): {'workers': 16, 'batch': 48, 'threads': 32},  # 96GBå†…å­˜ç³»ç»Ÿ
        (32, True): {'workers': 12, 'batch': 48, 'threads': 24},
        (96, True): {'workers': 16, 'batch': 64, 'threads': 32},
    }

    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        self.system = self._detect_system()
        logger.info(f"æ£€æµ‹åˆ°ç³»ç»Ÿ: {self.system.physical_cores}æ ¸{self.system.logical_cores}çº¿ç¨‹, "
                   f"{self.system.total_memory_gb:.1f}GBå†…å­˜")

    def _detect_system(self) -> SystemSpec:
        """æ£€æµ‹ç³»ç»Ÿè§„æ ¼"""
        physical_cores = psutil.cpu_count(logical=False) or 16
        logical_cores = psutil.cpu_count() or 32
        total_memory_gb = psutil.virtual_memory().total / (1024**3)
        available_memory_gb = psutil.virtual_memory().available / (1024**3)

        return SystemSpec(
            physical_cores=physical_cores,
            logical_cores=logical_cores,
            total_memory_gb=total_memory_gb,
            available_memory_gb=available_memory_gb
        )

    def calculate_optimal_workers(self) -> int:
        """
        è®¡ç®—æœ€ä¼˜workeræ•°é‡

        ç­–ç•¥ï¼š
        1. CPUå¯†é›†å‹ï¼šä½¿ç”¨ç‰©ç†æ ¸å¿ƒæ•°
        2. å†…å­˜å¯†é›†å‹ï¼šæ¯2GBå†…å­˜1ä¸ªworker
        3. å–è¾ƒå°å€¼ä»¥ç¡®ä¿ç¨³å®šæ€§
        """
        # åŸºäºCPU
        cpu_based = self.system.physical_cores

        # åŸºäºå†…å­˜ï¼ˆæ¯2GBå†…å­˜1ä¸ªworkerï¼‰
        mem_based = int(self.system.available_memory_gb / 2)

        # å–è¾ƒå°å€¼ï¼Œä½†è‡³å°‘4ä¸ª
        optimal = min(cpu_based, mem_based)
        return max(optimal, 4)

    def calculate_optimal_batch_size(self, workers: int, use_gpu: bool = False) -> int:
        """
        è®¡ç®—æœ€ä¼˜æ‰¹å¤„ç†å¤§å°

        ç­–ç•¥ï¼š
        - batch_sizeåº”è¯¥è®©æ‰€æœ‰workerä¿æŒå¿™ç¢Œ
        - ä½†ä¸èƒ½è¶…è¿‡å†…å­˜é™åˆ¶
        - è€ƒè™‘å†…å­˜ç¢ç‰‡å’Œå³°å€¼

        å…¬å¼ï¼š
        batch_size = min(
            å†…å­˜é™åˆ¶: å¯ç”¨å†…å­˜GB Ã— 1.5,
            CPUå¹¶è¡Œåº¦: workers Ã— 2,
            ä¸Šé™: æ ¹æ®æ€»å†…å­˜åŠ¨æ€è°ƒæ•´
                - 32GBä»¥ä¸‹: 32
                - 64GBä»¥ä¸‹: 48
                - 96GBåŠä»¥ä¸Š: 64
        )
        """
        if use_gpu:
            # GPUæ¨¡å¼ï¼šå‡è®¾æœ‰å……è¶³æ˜¾å­˜
            return 64 if self.system.total_memory_gb >= 64 else 48

        # CPUæ¨¡å¼
        available_gb = self.system.available_memory_gb
        total_gb = self.system.total_memory_gb

        # æ–¹æ³•1ï¼šåŸºäºå†…å­˜ï¼ˆæ¯GBå¯å¤„ç†çº¦1.5é¡µï¼‰
        mem_based_batch = int(available_gb * 1.5)

        # æ–¹æ³•2ï¼šåŸºäºCPUå¹¶è¡Œåº¦ï¼ˆæ¯ä¸ªworkerå¤„ç†2é¡µï¼‰
        cpu_based_batch = workers * 2

        # æ–¹æ³•3ï¼šåŸºäºæ ¸å¿ƒæ•°ï¼ˆæ¯ä¸ªç‰©ç†æ ¸å¿ƒå¤„ç†2é¡µï¼‰
        core_based_batch = self.system.physical_cores * 2

        # åŠ¨æ€ä¸Šé™ï¼šæ ¹æ®æ€»å†…å­˜è°ƒæ•´
        if total_gb >= 96:
            upper_limit = 64  # 96GBå†…å­˜å¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch
        elif total_gb >= 64:
            upper_limit = 48
        elif total_gb >= 32:
            upper_limit = 32
        else:
            upper_limit = 16

        # å–ä¸‰ç§æ–¹æ³•çš„æœ€å°å€¼
        batch_size = min(mem_based_batch, cpu_based_batch, core_based_batch, upper_limit)

        # è®¾ç½®ä¸‹é™
        batch_size = max(batch_size, 8)

        logger.debug(f"æ‰¹å¤„ç†å¤§å°è®¡ç®—: å†…å­˜={mem_based_batch}, "
                    f"CPUå¹¶è¡Œ={cpu_based_batch}, æ ¸å¿ƒ={core_based_batch}, "
                    f"ä¸Šé™={upper_limit}, é€‰å®š={batch_size}")

        return batch_size

    def get_optimal_config(self, enable_gpu: bool = False) -> OptimalConfig:
        """
        è·å–æœ€ä¼˜é…ç½®

        Returns:
            OptimalConfig: åŒ…å«æ‰€æœ‰ä¼˜åŒ–å‚æ•°çš„é…ç½®å¯¹è±¡
        """
        workers = self.calculate_optimal_workers()
        batch_size = self.calculate_optimal_batch_size(workers, enable_gpu)

        # è¡¨æ ¼æ‰¹å¤„ç†å¤§å°è¾ƒå°ï¼ˆè¡¨æ ¼å¤„ç†è¾ƒé‡ï¼‰
        table_batch_size = max(batch_size // 4, 2)

        # æœ€å¤§è¿›ç¨‹å†…å­˜ï¼šä½¿ç”¨70%å¯ç”¨å†…å­˜
        max_process_memory_gb = self.system.total_memory_gb * 0.70

        config = OptimalConfig(
            max_workers=workers,
            num_threads=self.system.logical_cores,  # ä½¿ç”¨æ‰€æœ‰é€»è¾‘æ ¸å¿ƒ
            ocr_batch_size=batch_size,
            layout_batch_size=batch_size,
            table_batch_size=table_batch_size,
            max_process_memory_gb=max_process_memory_gb
        )

        return config

    def print_recommendation(self, enable_gpu: bool = False):
        """æ‰“å°æ¨èé…ç½®ï¼ˆç¾åŒ–è¾“å‡ºï¼‰"""
        config = self.get_optimal_config(enable_gpu)

        # æ ¹æ®å†…å­˜å¤§å°é€‰æ‹©é…ç½®æ–‡ä»¶å
        if self.system.total_memory_gb >= 96:
            config_file = "config_amd_cpu_96gb.yaml"
        elif self.system.total_memory_gb >= 64:
            config_file = "config_amd_cpu_64gb.yaml"
        else:
            config_file = "config_amd_cpu_32core.yaml"

        # æ ¹æ®å†…å­˜å¤§å°ä¼°ç®—ååé‡
        if self.system.total_memory_gb >= 96:
            throughput = "0.6-0.8 é¡µ/ç§’"
        elif self.system.total_memory_gb >= 64:
            throughput = "0.5-0.7 é¡µ/ç§’"
        else:
            throughput = "0.4-0.6 é¡µ/ç§’"

        print("\n" + "=" * 70)
        print(" " * 15 + "ğŸš€ AMD CPU 16æ ¸å¿ƒæ€§èƒ½ä¼˜åŒ–æ¨èé…ç½®")
        print("=" * 70)

        print(f"\nğŸ“Š ç³»ç»Ÿä¿¡æ¯:")
        print(f"   ç‰©ç†æ ¸å¿ƒ: {self.system.physical_cores} æ ¸")
        print(f"   é€»è¾‘æ ¸å¿ƒ: {self.system.logical_cores} çº¿ç¨‹ (å«è¶…çº¿ç¨‹)")
        print(f"   æ€»å†…å­˜:   {self.system.total_memory_gb:.1f} GB")
        print(f"   å¯ç”¨å†…å­˜: {self.system.available_memory_gb:.1f} GB")

        print(f"\nğŸ¯ ä¼˜åŒ–ç­–ç•¥:")
        print(f"   è¿è¡Œæ¨¡å¼: {'GPUåŠ é€Ÿ' if enable_gpu else 'çº¯CPUæ¨¡å¼'}")

        print(f"\nâš™ï¸  æ¨èé…ç½®:")
        print(f"   max_workers:        {config.max_workers:2d}      # å¹¶å‘workeræ•°")
        print(f"   num_threads:        {config.num_threads:2d}      # æ€»çº¿ç¨‹æ•°")
        print(f"   ocr_batch_size:     {config.ocr_batch_size:2d}      # OCRæ‰¹å¤„ç†")
        print(f"   layout_batch_size:  {config.layout_batch_size:2d}      # å¸ƒå±€åˆ†ææ‰¹å¤„ç†")
        print(f"   table_batch_size:   {config.table_batch_size:2d}      # è¡¨æ ¼å¤„ç†æ‰¹å¤„ç†")

        print(f"\nğŸ’¾ é¢„æœŸèµ„æºä½¿ç”¨:")
        print(f"   CPUåˆ©ç”¨ç‡:          85-95%")
        print(f"   å†…å­˜ä½¿ç”¨:           {config.max_process_memory_gb:.1f} GB (å³°å€¼)")
        print(f"   ååé‡:            {throughput}")

        # ç”Ÿæˆå‘½ä»¤è¡Œ
        print(f"\nğŸ–¥ï¸  æ¨èå‘½ä»¤:")
        cmd = f"pdf2md convert report.pdf "
        cmd += f"--workers {config.max_workers} "
        cmd += f"--batch-size {config.ocr_batch_size}"
        if not enable_gpu:
            cmd += " --no-gpu"
        print(f"   {cmd}")

        # é…ç½®æ–‡ä»¶æ–¹å¼
        print(f"\nğŸ“„ æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶:")
        print(f"   cp {config_file} config.yaml")
        print(f"   pdf2md convert report.pdf")

        print("\n" + "=" * 70 + "\n")

        return config


class AdvancedMemoryManager:
    """
    é«˜çº§å†…å­˜ç®¡ç†å™¨

    æ”¯æŒåŠ¨æ€è°ƒæ•´å’Œè‡ªé€‚åº”é™çº§
    """

    def __init__(self, max_percent: float = 85.0, max_process_gb: Optional[float] = None):
        """
        åˆå§‹åŒ–å†…å­˜ç®¡ç†å™¨

        Args:
            max_percent: æœ€å¤§å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”
            max_process_gb: æœ€å¤§è¿›ç¨‹å†…å­˜ï¼ˆGBï¼‰
        """
        self.max_percent = max_percent
        self.max_process_bytes = int(max_process_gb * 1024**3) if max_process_gb else None

        # å†…å­˜ä½¿ç”¨å†å²ï¼ˆç”¨äºè¶‹åŠ¿åˆ†æï¼‰
        self.memory_history = []
        self.max_history = 100

    def get_available_gb(self) -> float:
        """è·å–å¯ç”¨å†…å­˜ï¼ˆGBï¼‰"""
        return psutil.virtual_memory().available / (1024**3)

    def get_memory_pressure(self) -> str:
        """
        æ£€æŸ¥å†…å­˜å‹åŠ›çº§åˆ«

        Returns:
            str: 'low', 'medium', 'high', 'critical'
        """
        available_gb = self.get_available_gb()
        percent = psutil.virtual_memory().percent

        if percent > 90 or available_gb < 2:
            return "critical"
        elif percent > 75 or available_gb < 4:
            return "high"
        elif percent > 60:
            return "medium"
        else:
            return "low"

    def should_reduce_batch_size(self, current_batch_size: int) -> bool:
        """
        æ˜¯å¦éœ€è¦é™ä½æ‰¹å¤„ç†å¤§å°

        Args:
            current_batch_size: å½“å‰æ‰¹å¤„ç†å¤§å°

        Returns:
            bool: æ˜¯å¦éœ€è¦é™ä½
        """
        pressure = self.get_memory_pressure()
        return pressure in ["high", "critical"]

    def recommend_batch_size(self, current_batch_size: int) -> int:
        """
        æ¨èæ–°çš„æ‰¹å¤„ç†å¤§å°

        Args:
            current_batch_size: å½“å‰æ‰¹å¤„ç†å¤§å°

        Returns:
            int: æ¨èçš„æ‰¹å¤„ç†å¤§å°
        """
        pressure = self.get_memory_pressure()

        if pressure == "critical":
            # å±æ€¥ï¼šé™ä½åˆ°1/4
            new_size = max(1, current_batch_size // 4)
            logger.warning(f"å†…å­˜å±æ€¥({self.get_available_gb():.1f}GBå¯ç”¨)ï¼Œ"
                          f"æ‰¹å¤„ç†å¤§å°: {current_batch_size} â†’ {new_size}")
            return new_size

        elif pressure == "high":
            # é«˜å‹åŠ›ï¼šé™ä½åˆ°1/2
            new_size = max(2, current_batch_size // 2)
            logger.warning(f"å†…å­˜å‹åŠ›é«˜({self.get_available_gb():.1f}GBå¯ç”¨)ï¼Œ"
                          f"æ‰¹å¤„ç†å¤§å°: {current_batch_size} â†’ {new_size}")
            return new_size

        else:
            # æ­£å¸¸ï¼šä¿æŒä¸å˜
            return current_batch_size

    def log_stats(self, context: str = ""):
        """è®°å½•å†…å­˜ç»Ÿè®¡"""
        available_gb = self.get_available_gb()
        percent = psutil.virtual_memory().percent
        pressure = self.get_memory_pressure()

        logger.info(f"å†…å­˜çŠ¶æ€[{context}]: "
                   f"å¯ç”¨={available_gb:.1f}GB ({percent}%), "
                   f"å‹åŠ›={pressure}")

        # è®°å½•å†å²
        self.memory_history.append({
            'context': context,
            'available_gb': available_gb,
            'percent': percent,
            'pressure': pressure
        })

        # é™åˆ¶å†å²é•¿åº¦
        if len(self.memory_history) > self.max_history:
            self.memory_history.pop(0)

    def force_cleanup(self):
        """å¼ºåˆ¶æ¸…ç†å†…å­˜"""
        logger.debug("æ‰§è¡Œåƒåœ¾å›æ”¶...")
        gc.collect()
        logger.debug(f"æ¸…ç†åå¯ç”¨å†…å­˜: {self.get_available_gb():.1f}GB")


def print_system_info():
    """æ‰“å°ç³»ç»Ÿä¿¡æ¯"""
    import platform

    print("\n" + "=" * 70)
    print(" " * 20 + "ç³»ç»Ÿä¿¡æ¯")
    print("=" * 70)

    # CPUä¿¡æ¯
    print(f"\nå¤„ç†å™¨ (CPU):")
    print(f"   ç‰©ç†æ ¸å¿ƒ: {psutil.cpu_count(logical=False)}")
    print(f"   é€»è¾‘æ ¸å¿ƒ: {psutil.cpu_count()}")
    print(f"   é¢‘ç‡: {psutil.cpu_freq().max if psutil.cpu_freq() else 'N/A'} MHz")

    # å†…å­˜ä¿¡æ¯
    mem = psutil.virtual_memory()
    print(f"\nå†…å­˜ (RAM):")
    print(f"   æ€»å®¹é‡: {mem.total / (1024**3):.1f} GB")
    print(f"   å¯ç”¨:   {mem.available / (1024**3):.1f} GB")
    print(f"   ä½¿ç”¨ç‡: {mem.percent}%")

    # ç³»ç»Ÿä¿¡æ¯
    print(f"\nç³»ç»Ÿ:")
    print(f"   å¹³å°:   {platform.system()} {platform.release()}")
    print(f"   æ¶æ„:   {platform.machine()}")

    # Pythonä¿¡æ¯
    print(f"\nPython:")
    print(f"   ç‰ˆæœ¬:   {platform.python_version()}")

    print("=" * 70 + "\n")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print_system_info()

    optimizer = AMDCPUOptimizer()
    config = optimizer.print_recommendation(enable_gpu=False)

    print("\næ¨èé…ç½®è¯¦æƒ…:")
    for key, value in config.to_dict().items():
        print(f"  {key}: {value}")
